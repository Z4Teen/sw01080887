{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a44d574",
   "metadata": {},
   "source": [
    "# Task 1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18356abc",
   "metadata": {},
   "source": [
    "*Note that only 10000 rows are used to reduce computational power needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "569cfc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "345b5a28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/Z4Teen/Desktop/Anaconda Jupiter/data/Amazon.csv\", encoding=\"ISO-8859-1\", nrows=10000)\n",
    "data['Text'].astype(str).drop_duplicates().dropna()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e304f015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "num_duplicates = data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {num_duplicates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "520e79ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Z4Teen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Z4Teen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# Ensure you have the necessary NLTK data files\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab6f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stop words and convert to lowercase\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word.lower() for word in words if word.lower() not in stop_words]\n",
    "    # Join words back into a single string\n",
    "    cleaned_text = ' '.join(words)\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12e64991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "3                     3                       3      2  1307923200   \n",
      "4                     0                       0      5  1350777600   \n",
      "\n",
      "                 Summary                                               Text  \\\n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
      "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
      "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
      "\n",
      "                                        Cleaned_Text  \n",
      "0  bought several vitality canned dog food produc...  \n",
      "1  product arrived labeled jumbo salted peanutsth...  \n",
      "2  confection around centuries light pillowy citr...  \n",
      "3  looking secret ingredient robitussin believe f...  \n",
      "4  great taffy great price wide assortment yummy ...  \n"
     ]
    }
   ],
   "source": [
    "data['Cleaned_Text'] = data['Text'].astype(str).apply(clean_text)\n",
    "print(data.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f900b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tokenized_Text'] = data['Cleaned_Text'].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79807c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Tokenized_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>[bought, several, vitality, canned, dog, food,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arrived labeled jumbo salted peanutsth...</td>\n",
       "      <td>[product, arrived, labeled, jumbo, salted, pea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>[confection, around, centuries, light, pillowy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>[looking, secret, ingredient, robitussin, beli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>[great, taffy, great, price, wide, assortment,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                        Cleaned_Text  \\\n",
       "0  bought several vitality canned dog food produc...   \n",
       "1  product arrived labeled jumbo salted peanutsth...   \n",
       "2  confection around centuries light pillowy citr...   \n",
       "3  looking secret ingredient robitussin believe f...   \n",
       "4  great taffy great price wide assortment yummy ...   \n",
       "\n",
       "                                      Tokenized_Text  \n",
       "0  [bought, several, vitality, canned, dog, food,...  \n",
       "1  [product, arrived, labeled, jumbo, salted, pea...  \n",
       "2  [confection, around, centuries, light, pillowy...  \n",
       "3  [looking, secret, ingredient, robitussin, beli...  \n",
       "4  [great, taffy, great, price, wide, assortment,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eebab75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Z4Teen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Z4Teen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Tokenized_Text</th>\n",
       "      <th>Stemmed_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>[bought, several, vitality, canned, dog, food,...</td>\n",
       "      <td>[bought, sever, vital, can, dog, food, product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arrived labeled jumbo salted peanutsth...</td>\n",
       "      <td>[product, arrived, labeled, jumbo, salted, pea...</td>\n",
       "      <td>[product, arriv, label, jumbo, salt, peanutsth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>[confection, around, centuries, light, pillowy...</td>\n",
       "      <td>[confect, around, centuri, light, pillowi, cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>[looking, secret, ingredient, robitussin, beli...</td>\n",
       "      <td>[look, secret, ingredi, robitussin, believ, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>[great, taffy, great, price, wide, assortment,...</td>\n",
       "      <td>[great, taffi, great, price, wide, assort, yum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                        Cleaned_Text  \\\n",
       "0  bought several vitality canned dog food produc...   \n",
       "1  product arrived labeled jumbo salted peanutsth...   \n",
       "2  confection around centuries light pillowy citr...   \n",
       "3  looking secret ingredient robitussin believe f...   \n",
       "4  great taffy great price wide assortment yummy ...   \n",
       "\n",
       "                                      Tokenized_Text  \\\n",
       "0  [bought, several, vitality, canned, dog, food,...   \n",
       "1  [product, arrived, labeled, jumbo, salted, pea...   \n",
       "2  [confection, around, centuries, light, pillowy...   \n",
       "3  [looking, secret, ingredient, robitussin, beli...   \n",
       "4  [great, taffy, great, price, wide, assortment,...   \n",
       "\n",
       "                                        Stemmed_Text  \n",
       "0  [bought, sever, vital, can, dog, food, product...  \n",
       "1  [product, arriv, label, jumbo, salt, peanutsth...  \n",
       "2  [confect, around, centuri, light, pillowi, cit...  \n",
       "3  [look, secret, ingredi, robitussin, believ, fo...  \n",
       "4  [great, taffi, great, price, wide, assort, yum...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Ensure you have the necessary NLTK data files\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize the Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "    stem_text = []\n",
    "    for word in text:\n",
    "        stemmed_word = stemmer.stem(word)\n",
    "        stem_text.append(stemmed_word)\n",
    "    return stem_text\n",
    "\n",
    "data['Stemmed_Text'] = data['Tokenized_Text'].apply(stemming)\n",
    "data.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be12f103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Tokenized_Text</th>\n",
       "      <th>Stemmed_Text</th>\n",
       "      <th>Lemmatized_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>[bought, several, vitality, canned, dog, food,...</td>\n",
       "      <td>[bought, sever, vital, can, dog, food, product...</td>\n",
       "      <td>[bought, sever, vital, can, dog, food, product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arrived labeled jumbo salted peanutsth...</td>\n",
       "      <td>[product, arrived, labeled, jumbo, salted, pea...</td>\n",
       "      <td>[product, arriv, label, jumbo, salt, peanutsth...</td>\n",
       "      <td>[product, arriv, label, jumbo, salt, peanutsth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>[confection, around, centuries, light, pillowy...</td>\n",
       "      <td>[confect, around, centuri, light, pillowi, cit...</td>\n",
       "      <td>[confect, around, centuri, light, pillowi, cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>[looking, secret, ingredient, robitussin, beli...</td>\n",
       "      <td>[look, secret, ingredi, robitussin, believ, fo...</td>\n",
       "      <td>[look, secret, ingredi, robitussin, believ, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>[great, taffy, great, price, wide, assortment,...</td>\n",
       "      <td>[great, taffi, great, price, wide, assort, yum...</td>\n",
       "      <td>[great, taffi, great, price, wide, assort, yum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                        Cleaned_Text  \\\n",
       "0  bought several vitality canned dog food produc...   \n",
       "1  product arrived labeled jumbo salted peanutsth...   \n",
       "2  confection around centuries light pillowy citr...   \n",
       "3  looking secret ingredient robitussin believe f...   \n",
       "4  great taffy great price wide assortment yummy ...   \n",
       "\n",
       "                                      Tokenized_Text  \\\n",
       "0  [bought, several, vitality, canned, dog, food,...   \n",
       "1  [product, arrived, labeled, jumbo, salted, pea...   \n",
       "2  [confection, around, centuries, light, pillowy...   \n",
       "3  [looking, secret, ingredient, robitussin, beli...   \n",
       "4  [great, taffy, great, price, wide, assortment,...   \n",
       "\n",
       "                                        Stemmed_Text  \\\n",
       "0  [bought, sever, vital, can, dog, food, product...   \n",
       "1  [product, arriv, label, jumbo, salt, peanutsth...   \n",
       "2  [confect, around, centuri, light, pillowi, cit...   \n",
       "3  [look, secret, ingredi, robitussin, believ, fo...   \n",
       "4  [great, taffi, great, price, wide, assort, yum...   \n",
       "\n",
       "                                     Lemmatized_Text  \n",
       "0  [bought, sever, vital, can, dog, food, product...  \n",
       "1  [product, arriv, label, jumbo, salt, peanutsth...  \n",
       "2  [confect, around, centuri, light, pillowi, cit...  \n",
       "3  [look, secret, ingredi, robitussin, believ, fo...  \n",
       "4  [great, taffi, great, price, wide, assort, yum...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatization(text):\n",
    "    lem_text = []\n",
    "    for word in text:\n",
    "        lem_word = lemmatizer.lemmatize(word)\n",
    "        lem_text.append(lem_word)\n",
    "    return lem_text\n",
    "\n",
    "data['Lemmatized_Text'] = data['Stemmed_Text'].apply(lemmatization)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d714fb",
   "metadata": {},
   "source": [
    "# Task 2 Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b27a70ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fcc2c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(document):\n",
    "    word_count = Counter(document)\n",
    "    tf = {word: count/len(document) for word, count in word_count.items()}\n",
    "    return tf\n",
    "\n",
    "def compute_idf(documents):\n",
    "    N = len(documents)\n",
    "    idf = {}\n",
    "    all_words = set(word for doc in documents for word in doc)\n",
    "    for word in all_words:\n",
    "        count = sum(1 for doc in documents if word in doc)\n",
    "        idf[word] = math.log(N/count)\n",
    "    return idf\n",
    "\n",
    "def compute_tfidf(document, idf):\n",
    "    tfidf = {}\n",
    "    tf = compute_tf(document)\n",
    "    for word, tf_value in tf.items():\n",
    "        tfidf[word] = tf_value * idf[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1684f987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Scores:\n",
      "        bought     sever     vital       can       dog      food   product  \\\n",
      "0     0.043478  0.043478  0.043478  0.043478  0.043478  0.043478  0.130435   \n",
      "1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.111111   \n",
      "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  0.000000  0.000000  0.000000  0.000000  0.000000  0.024390  0.048780   \n",
      "9996  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "9997  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.013158   \n",
      "9998  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "9999  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "         found      good   qualiti  ...  ulterior  sucrosewel     hexan  \\\n",
      "0     0.043478  0.043478  0.043478  ...       0.0    0.000000  0.000000   \n",
      "1     0.000000  0.000000  0.000000  ...       0.0    0.000000  0.000000   \n",
      "2     0.000000  0.000000  0.000000  ...       0.0    0.000000  0.000000   \n",
      "3     0.055556  0.055556  0.000000  ...       0.0    0.000000  0.000000   \n",
      "4     0.000000  0.000000  0.000000  ...       0.0    0.000000  0.000000   \n",
      "...        ...       ...       ...  ...       ...         ...       ...   \n",
      "9995  0.000000  0.000000  0.000000  ...       0.0    0.000000  0.000000   \n",
      "9996  0.000000  0.000000  0.000000  ...       0.0    0.000000  0.000000   \n",
      "9997  0.013158  0.000000  0.000000  ...       0.0    0.013158  0.039474   \n",
      "9998  0.000000  0.000000  0.000000  ...       0.0    0.000000  0.000000   \n",
      "9999  0.000000  0.000000  0.000000  ...       0.0    0.000000  0.000000   \n",
      "\n",
      "      arsenicuh    deliev   delievi  chargeit  formular    midwif     amazn  \n",
      "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "2      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "9995   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "9996   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "9997   0.013158  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "9998   0.000000  0.090909  0.090909  0.090909  0.090909  0.000000  0.000000  \n",
      "9999   0.000000  0.000000  0.000000  0.000000  0.000000  0.010309  0.010309  \n",
      "\n",
      "[10000 rows x 18974 columns]\n",
      "\n",
      "IDF Scores:\n",
      "   balsamico  meuntil    cornbr  hrefhttpwwwamazoncomgpproductb005k4q1t0grov  \\\n",
      "0    9.21034  9.21034  7.600902                                      9.21034   \n",
      "\n",
      "   freshbrew  yearsnow  increasebr  overrun   yawnim      demo  ...  standard  \\\n",
      "0   8.517193   9.21034     9.21034  9.21034  9.21034  8.517193  ...  4.906275   \n",
      "\n",
      "   paintbrush    outdon    minebr  inferior      mola  flavorsa   mexican  \\\n",
      "0     9.21034  8.517193  8.517193  6.907755  6.165818   9.21034  6.074846   \n",
      "\n",
      "     matter      fine  \n",
      "0  4.710531  3.705009  \n",
      "\n",
      "[1 rows x 18974 columns]\n",
      "\n",
      "TF-IDF Scores:\n",
      "        bought     sever     vital       can       dog      food   product  \\\n",
      "0     0.110859  0.145018  0.310039  0.155927  0.129817  0.096928  0.205818   \n",
      "1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.175327   \n",
      "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  0.000000  0.000000  0.000000  0.000000  0.000000  0.054374  0.076973   \n",
      "9996  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "9997  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.020762   \n",
      "9998  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "9999  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "         found      good   qualiti  ...  ulterior  sucrosewel     hexan  \\\n",
      "0     0.108794  0.057057  0.130249  ...       0.0    0.000000  0.000000   \n",
      "1     0.000000  0.000000  0.000000  ...       0.0    0.000000  0.000000   \n",
      "2     0.000000  0.000000  0.000000  ...       0.0    0.000000  0.000000   \n",
      "3     0.139014  0.072906  0.000000  ...       0.0    0.000000  0.000000   \n",
      "4     0.000000  0.000000  0.000000  ...       0.0    0.000000  0.000000   \n",
      "...        ...       ...       ...  ...       ...         ...       ...   \n",
      "9995  0.000000  0.000000  0.000000  ...       0.0    0.000000  0.000000   \n",
      "9996  0.000000  0.000000  0.000000  ...       0.0    0.000000  0.000000   \n",
      "9997  0.032924  0.000000  0.000000  ...       0.0    0.121189  0.363566   \n",
      "9998  0.000000  0.000000  0.000000  ...       0.0    0.000000  0.000000   \n",
      "9999  0.000000  0.000000  0.000000  ...       0.0    0.000000  0.000000   \n",
      "\n",
      "      arsenicuh    deliev   delievi  chargeit  formular    midwif     amazn  \n",
      "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "2      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "9995   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "9996   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "9997   0.121189  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "9998   0.000000  0.837304  0.837304  0.837304  0.837304  0.000000  0.000000  \n",
      "9999   0.000000  0.000000  0.000000  0.000000  0.000000  0.094952  0.094952  \n",
      "\n",
      "[10000 rows x 18974 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute TF for each document\n",
    "tf_data = [compute_tf(doc) for doc in data['Lemmatized_Text']]\n",
    "\n",
    "# Create DataFrame for TF\n",
    "tf_df = pd.DataFrame(tf_data).fillna(0)\n",
    "print(\"TF Scores:\")\n",
    "print(tf_df)\n",
    "\n",
    "# Compute IDF\n",
    "idf = compute_idf(data['Lemmatized_Text'])\n",
    "idf_df = pd.DataFrame([idf]).fillna(0)\n",
    "print(\"\\nIDF Scores:\")\n",
    "print(idf_df)\n",
    "\n",
    "# Compute TF-IDF for each document\n",
    "tfidf_data = [compute_tfidf(doc, idf) for doc in data['Lemmatized_Text']]\n",
    "\n",
    "# Create DataFrame for TF-IDF\n",
    "tfidf_df = pd.DataFrame(tfidf_data).fillna(0)\n",
    "print(\"\\nTF-IDF Scores:\")\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "050cd970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Tokenized_Text</th>\n",
       "      <th>Stemmed_Text</th>\n",
       "      <th>Lemmatized_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>[bought, several, vitality, canned, dog, food,...</td>\n",
       "      <td>[bought, sever, vital, can, dog, food, product...</td>\n",
       "      <td>[bought, sever, vital, can, dog, food, product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arrived labeled jumbo salted peanutsth...</td>\n",
       "      <td>[product, arrived, labeled, jumbo, salted, pea...</td>\n",
       "      <td>[product, arriv, label, jumbo, salt, peanutsth...</td>\n",
       "      <td>[product, arriv, label, jumbo, salt, peanutsth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>[confection, around, centuries, light, pillowy...</td>\n",
       "      <td>[confect, around, centuri, light, pillowi, cit...</td>\n",
       "      <td>[confect, around, centuri, light, pillowi, cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>[looking, secret, ingredient, robitussin, beli...</td>\n",
       "      <td>[look, secret, ingredi, robitussin, believ, fo...</td>\n",
       "      <td>[look, secret, ingredi, robitussin, believ, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>[great, taffy, great, price, wide, assortment,...</td>\n",
       "      <td>[great, taffi, great, price, wide, assort, yum...</td>\n",
       "      <td>[great, taffi, great, price, wide, assort, yum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "0                     1                       1  positive  1303862400   \n",
       "1                     0                       0  negative  1346976000   \n",
       "2                     1                       1  positive  1219017600   \n",
       "3                     3                       3  negative  1307923200   \n",
       "4                     0                       0  positive  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                        Cleaned_Text  \\\n",
       "0  bought several vitality canned dog food produc...   \n",
       "1  product arrived labeled jumbo salted peanutsth...   \n",
       "2  confection around centuries light pillowy citr...   \n",
       "3  looking secret ingredient robitussin believe f...   \n",
       "4  great taffy great price wide assortment yummy ...   \n",
       "\n",
       "                                      Tokenized_Text  \\\n",
       "0  [bought, several, vitality, canned, dog, food,...   \n",
       "1  [product, arrived, labeled, jumbo, salted, pea...   \n",
       "2  [confection, around, centuries, light, pillowy...   \n",
       "3  [looking, secret, ingredient, robitussin, beli...   \n",
       "4  [great, taffy, great, price, wide, assortment,...   \n",
       "\n",
       "                                        Stemmed_Text  \\\n",
       "0  [bought, sever, vital, can, dog, food, product...   \n",
       "1  [product, arriv, label, jumbo, salt, peanutsth...   \n",
       "2  [confect, around, centuri, light, pillowi, cit...   \n",
       "3  [look, secret, ingredi, robitussin, believ, fo...   \n",
       "4  [great, taffi, great, price, wide, assort, yum...   \n",
       "\n",
       "                                     Lemmatized_Text  \n",
       "0  [bought, sever, vital, can, dog, food, product...  \n",
       "1  [product, arriv, label, jumbo, salt, peanutsth...  \n",
       "2  [confect, around, centuri, light, pillowi, cit...  \n",
       "3  [look, secret, ingredi, robitussin, believ, fo...  \n",
       "4  [great, taffi, great, price, wide, assort, yum...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Score'] = data['Score'].replace({1: 'negative', 2: 'negative', 3: 'neutral', 4: 'positive', 5: 'positive'})\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf56f63",
   "metadata": {},
   "source": [
    "# Task 3 Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bb37ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7953628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e660b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Z4Teen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Z4Teen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Z4Teen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Tokenized_Text</th>\n",
       "      <th>Stemmed_Text</th>\n",
       "      <th>Lemmatized_Text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>[bought, several, vitality, canned, dog, food,...</td>\n",
       "      <td>[bought, sever, vital, can, dog, food, product...</td>\n",
       "      <td>[bought, sever, vital, can, dog, food, product...</td>\n",
       "      <td>bought sever vital can dog food product found ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arrived labeled jumbo salted peanutsth...</td>\n",
       "      <td>[product, arrived, labeled, jumbo, salted, pea...</td>\n",
       "      <td>[product, arriv, label, jumbo, salt, peanutsth...</td>\n",
       "      <td>[product, arriv, label, jumbo, salt, peanutsth...</td>\n",
       "      <td>product arriv label jumbo salt peanutsth peanu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>[confection, around, centuries, light, pillowy...</td>\n",
       "      <td>[confect, around, centuri, light, pillowi, cit...</td>\n",
       "      <td>[confect, around, centuri, light, pillowi, cit...</td>\n",
       "      <td>confect around centuri light pillowi citru gel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>[looking, secret, ingredient, robitussin, beli...</td>\n",
       "      <td>[look, secret, ingredi, robitussin, believ, fo...</td>\n",
       "      <td>[look, secret, ingredi, robitussin, believ, fo...</td>\n",
       "      <td>look secret ingredi robitussin believ found go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>[great, taffy, great, price, wide, assortment,...</td>\n",
       "      <td>[great, taffi, great, price, wide, assort, yum...</td>\n",
       "      <td>[great, taffi, great, price, wide, assort, yum...</td>\n",
       "      <td>great taffi great price wide assort yummi taff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "0                     1                       1  positive  1303862400   \n",
       "1                     0                       0  negative  1346976000   \n",
       "2                     1                       1  positive  1219017600   \n",
       "3                     3                       3  negative  1307923200   \n",
       "4                     0                       0  positive  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                        Cleaned_Text  \\\n",
       "0  bought several vitality canned dog food produc...   \n",
       "1  product arrived labeled jumbo salted peanutsth...   \n",
       "2  confection around centuries light pillowy citr...   \n",
       "3  looking secret ingredient robitussin believe f...   \n",
       "4  great taffy great price wide assortment yummy ...   \n",
       "\n",
       "                                      Tokenized_Text  \\\n",
       "0  [bought, several, vitality, canned, dog, food,...   \n",
       "1  [product, arrived, labeled, jumbo, salted, pea...   \n",
       "2  [confection, around, centuries, light, pillowy...   \n",
       "3  [looking, secret, ingredient, robitussin, beli...   \n",
       "4  [great, taffy, great, price, wide, assortment,...   \n",
       "\n",
       "                                        Stemmed_Text  \\\n",
       "0  [bought, sever, vital, can, dog, food, product...   \n",
       "1  [product, arriv, label, jumbo, salt, peanutsth...   \n",
       "2  [confect, around, centuri, light, pillowi, cit...   \n",
       "3  [look, secret, ingredi, robitussin, believ, fo...   \n",
       "4  [great, taffi, great, price, wide, assort, yum...   \n",
       "\n",
       "                                     Lemmatized_Text  \\\n",
       "0  [bought, sever, vital, can, dog, food, product...   \n",
       "1  [product, arriv, label, jumbo, salt, peanutsth...   \n",
       "2  [confect, around, centuri, light, pillowi, cit...   \n",
       "3  [look, secret, ingredi, robitussin, believ, fo...   \n",
       "4  [great, taffi, great, price, wide, assort, yum...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  bought sever vital can dog food product found ...  \n",
       "1  product arriv label jumbo salt peanutsth peanu...  \n",
       "2  confect around centuri light pillowi citru gel...  \n",
       "3  look secret ingredi robitussin believ found go...  \n",
       "4  great taffi great price wide assort yummi taff...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the WordNet Lemmatizer and Porter Stemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Lemmatize the words\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # Stem the words\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    # Join words back into a single string\n",
    "    cleaned_text = ' '.join(words)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "data['clean_text'] = data['Cleaned_Text'].astype(str).apply(preprocess)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b2df39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data is saved to: extracteddata.csv\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'extracteddata.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"Extracted data is saved to:\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfabfb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data['clean_text'])\n",
    "y = data['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d186196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c850b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3b32325",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb_classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd215c3",
   "metadata": {},
   "source": [
    "# Task 4 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a3e7392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7606666666666667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       480\n",
      "     neutral       0.00      0.00      0.00       238\n",
      "    positive       0.76      1.00      0.86      2282\n",
      "\n",
      "    accuracy                           0.76      3000\n",
      "   macro avg       0.25      0.33      0.29      3000\n",
      "weighted avg       0.58      0.76      0.66      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z4Teen\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Z4Teen\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Z4Teen\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "602977c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83d151ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiment using classifiers\n",
    "for text, actual_label in zip(X_test, y_test):\n",
    "    # Predict sentiment using Naive Bayes\n",
    "    nb_prediction = nb_classifier.predict(text)[0]\n",
    "\n",
    "    # Predict sentiment using SVM\n",
    "    svm_prediction = svm_classifier.predict(text)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9011322a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z4Teen\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Z4Teen\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Z4Teen\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       480\n",
      "     neutral       0.00      0.00      0.00       238\n",
      "    positive       0.76      1.00      0.86      2282\n",
      "\n",
      "    accuracy                           0.76      3000\n",
      "   macro avg       0.25      0.33      0.29      3000\n",
      "weighted avg       0.58      0.76      0.66      3000\n",
      "\n",
      "\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.48      0.59       480\n",
      "     neutral       0.65      0.09      0.16       238\n",
      "    positive       0.84      0.98      0.90      2282\n",
      "\n",
      "    accuracy                           0.83      3000\n",
      "   macro avg       0.75      0.52      0.55      3000\n",
      "weighted avg       0.81      0.83      0.79      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report for Naive Bayes\n",
    "nb_classification_report = classification_report(y_test, nb_classifier.predict(X_test), target_names=['negative', 'neutral', 'positive'])\n",
    "\n",
    "# Calculate classification report for SVM\n",
    "svm_classification_report = classification_report(y_test, svm_classifier.predict(X_test), target_names=['negative', 'neutral', 'positive'])\n",
    "\n",
    "# Print classification report for Naive Bayes\n",
    "print(\"\\nClassification Report for Naive Bayes:\")\n",
    "print(nb_classification_report)\n",
    "\n",
    "# Print classification report for SVM\n",
    "print(\"\\nClassification Report for SVM:\")\n",
    "print(svm_classification_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa668b2",
   "metadata": {},
   "source": [
    "# Task 5 Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5779afb",
   "metadata": {},
   "source": [
    "Naive Bayes \n",
    "\n",
    "Strength\n",
    "Naive Bayes is suitable to handle large dataset\n",
    "Easy to implement and understand\n",
    "\n",
    "Weakness\n",
    "Naive Bayes assumes all feature are equally independent, might lead to lower performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50f8395",
   "metadata": {},
   "source": [
    "SVM\n",
    "\n",
    "Strength\n",
    "Efficient with dimensional data\n",
    "Less prone to overfit\n",
    "\n",
    "Weakness\n",
    "Very computationally intensive with large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fcdb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
